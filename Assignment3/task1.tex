\section{Decision Trees (task 1)}

\section*{Attributes}
	\begin{itemize}
		\item Age: which may have values {Young, Medium young, Old}
		\item Income: that may have values {Low, Medium, High}
		\item Student: who may have values {yes, no}
		\item Creditworthiness: that can have values {Pass, High}
		\item Buy a PC: can have values {yes, no}
	\end{itemize}

\section*{Gini Index}

	
		\begin{equation}
		Gini(t) = 1 - \sum_{i=0}^{c-1} [p(i|t)]^{2} 
		\end{equation}
	
		c = number of classes \\
		p(i$|$t) = fraction of records belonging to class i


\section*{Questions} 
	
		\subsection*{1) Compute the Gini index for the entire training set}

		The Gini for the whole training set will be to calculate the Gini for the 
		class "Buy PC".

		\begin{table}[H]
			\begin{tabular}{ l | c }
				 & Buy PC \\ \hline
				Yes & 12 \\ \hline
				No & 8 \\ \hline
				Total & 20 \\
			\end{tabular}
		\end{table}

		$Gini(Buy PC) = 1 - (12/20)^{2} - (8/20)^{2} = 0.48$

		\clearpage
		\subsection*{2) Compute the Gini index for the UserID attribute}

		When splitting the data by UserID we will have 20 nodes and each 
		has the Gini index of 0. 

		\begin{table}[H]
			\begin{tabular}{ l | l | l | l | l | l | l | l | l | l | l |l | l | l }
				 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & ..... & 16 & 17 & 18 & 19 & 20  \\ \hline
				Yes & 0 & 0 & 1 & 1 & 1 & 0 & 1 & ..... & 1 & 1 & 0 & 0 & 1  \\ \hline 
				No & 1 & 1 & 0 & 0 & 0 & 1 & 0 & ..... & 0 & 0 & 1 & 1 & 0  \\ \hline
				Totalt & 1 & 1 & 1 & 1 & 1 & 1 & 1 & ..... & 1 & 1 & 1 & 1 & 1 \\
			\end{tabular}
		\end{table}

		The average weighted of the Gini index for the nodes is:

		$ Gini(UserID = 1) = 1 - (0/1)^{2} - (1/1)^{2} = 0 $

		(Gini for each UserID is the same for UserID 1-20)

		$ Gini(UserID) = (1/20)*0 + (1/20)*0 + .... + (1/20)*0 = 0 $



		\subsection*{3) Compute the Gini index for the Age attribute.}

		\begin{table}[H]
			\begin{tabular}{ c | c | c | c  }
				 & Young & Medium young & old  \\ \hline
				Yes & 4 & 5 & 3 \\ \hline
				No & 3 & 1 & 4 \\ \hline
				Total & 7 & 6 & 7 \\
			\end{tabular}
		\end{table}

		$Gini(Young) = 1 - (4/7)^{2} - (3/7)^{2} = 0.4898$

		$Gini(Medium young) = 1 - (4/7)^{2} - (3/7)^{2} = 0.2778$

		$Gini(old) = 1 - (4/7)^{2} - (3/7)^{2} = 0.4898$
		
		$Gini(Age) = (7/20)*0.4898 + (6/20)*0.2778 + (7/20)*0.4898 = 0.4262$		


		\clearpage
		\subsection*{4) Compute the Gini index for Student attribute.}

		\begin{table}[H]
			\begin{tabular}{ c | c | c }
				 & Yes & No   \\ \hline
				Yes & 8 & 4 \\ \hline
				No & 2 & 6 \\ \hline
				Total & 10 & 10 \\
			\end{tabular}
		\end{table}

		$Gini(Yes) = 1 - (8/10)^{2} - (2/10)^{2} = 0.32$

		$Gini(No) = 1 - (4/10)^{2} - (6/10)^{2} = 0.48$
		
		$Gini(Student) = (10/20)*0.32 + (10/20)*0.48 = 0.4$


		\subsection*{5) Compute the Gini index for Creditworthiness attribute.}

		\begin{table}[H]
			\begin{tabular}{ c | c | c }
				 & Pass & High   \\ \hline
				Yes & 6 & 6 \\ \hline
				No & 4 & 4 \\ \hline
				Total & 10 & 10 \\
			\end{tabular}
		\end{table}

		$Gini(Pass) = 1 - (6/10)^{2} - (4/10)^{2} = 0.48$

		$Gini(High) = 1 - (6/10)^{2} - (4/10)^{2} = 0.48$
		
		$Gini(Creditworthiness) = (10/20)*0.48 + (10/20)*0.48 = 0.48$

		
		\subsection*{6) Which attribute is the best?}

		\begin{table}[H]
			\begin{tabular}{ c | c | c | c | c | c }
				 & UserID & Age & Student & Creditwrthiness & Buy PC \\ \hline
				Gini Index & 0 & 0.4262 & 0.4 & 0.48 & 0.48 \\ 
			\end{tabular}
		\end{table}

		Thee smaller the degree of impurity, the clearer the class distribution. 
		Therefore the attribute Student = 0.4 is the best attribute to split by.

		As we can see in the table above, the UserID has a Gini index of 0 and has 
		a lower Gini index than student. The reason why we have selected Student over
		UserID is because UserID is the “primary key” (unique) for each 
		record, therefore it cannot be used as the attribute for splitting.


		\clearpage
		\subsection*{Explain Decision Tree procedure}

		Suppose we have the following two users we want to predict whether they
		should be able to buy a PC or not. Explain how you want to proceed.
		
		\begin{itemize}
			\item {\bf UserID 21:} A young student with medium income and “high” 
			creditworthiness.
			\item {\bf UserID 22:} A young non-student with low income and “pass” 
			creditworthiness.
		\end{itemize}

		To predict if a user want to buy a PC or not is a good situation to build a
		decision tree. The way to build a decision tree is to use the training data
		set and build a tree by always pick the attribute with the lowest Gini index.
		If the leaf node in the tree does not have a specified class, split until
		all leaf nodes is a specified class node. 

		When I have my decision tree I can easily follow the tree to I get to a leaf
		node that will tell the prediction for a specific record.
